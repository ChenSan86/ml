"""
ä¸€ä½“åŒ–è„šæœ¬ï¼šè®­ç»ƒ + è¯„ä¼° åŸºçº¿(BiLSTM) ä¸ å¢å¼ºç‰ˆ(èåˆç‰¹å¾å·¥ç¨‹)

åŠŸèƒ½ï¼š
- æ¨¡å¼ allï¼šä¾æ¬¡è®­ç»ƒåŸºçº¿ä¸å¢å¼ºç‰ˆï¼Œå¹¶åœ¨ç»Ÿä¸€ 9:1 éªŒè¯é›†ä¸Šè¯„ä¼°ã€‚
- æ¨¡å¼ evalï¼šè·³è¿‡è®­ç»ƒï¼Œç›´æ¥è¯„ä¼°å·²æœ‰æƒé‡ï¼ˆbest_model.pth ä¸ best_model_enhanced.pthï¼‰ã€‚
- æ¨¡å¼ trainï¼šä»…è®­ç»ƒä¸¤ç§æ¨¡å‹ï¼Œä¸è¯„ä¼°ï¼ˆå¿«é€Ÿè°ƒè¯•æ—¶ä½¿ç”¨ï¼‰ã€‚
- æ”¯æŒ --quick å°† EPOCHS æš‚æ—¶æ”¹ä¸º 3ã€‚

è¯„ä¼°è¾“å‡ºï¼šAUCã€åˆ†ç±»æŠ¥å‘Šã€æ··æ·†çŸ©é˜µä¸é¢„æµ‹åˆ†å¸ƒå›¾ï¼ˆç”± predict.py å®Œæˆï¼‰
ç»“æœæ•´åˆï¼šæœ¬è„šæœ¬ä¼šå°†ä¸¤è€… AUC æ±‡æ€»åˆ° results_baseline_enhanced.csv
"""

import argparse
import csv
from datetime import datetime

from config import config
from dataset import prepare_data
from train import train as train_baseline
from train_enhanced import train_enhanced
from predict import evaluate_model, evaluate_enhanced_model


def write_summary_csv(baseline_auc, enhanced_auc, output_file='results_baseline_enhanced.csv'):
    """å†™å…¥å¯¹æ¯”ç»“æœåˆ°CSV"""
    with open(output_file, 'w', newline='') as f:
        writer = csv.writer(f)
        writer.writerow(['timestamp', 'model', 'auc'])
        ts = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        writer.writerow([ts, 'baseline', f'{baseline_auc:.6f}'])
        writer.writerow([ts, 'enhanced', f'{enhanced_auc:.6f}'])
    print(f"\nğŸ’¾ ç»“æœå·²å†™å…¥: {output_file}")


def main():
    parser = argparse.ArgumentParser(description='è®­ç»ƒ+è¯„ä¼° åŸºçº¿ ä¸ å¢å¼ºç‰ˆï¼ˆç‰¹å¾å·¥ç¨‹ï¼‰æ¨¡å‹')
    parser.add_argument('--mode', type=str, default='all', choices=['train', 'eval', 'all'],
                        help='è¿è¡Œæ¨¡å¼ï¼štrain(è®­ç»ƒ)ã€eval(è¯„ä¼°ç°æœ‰æƒé‡)ã€all(è®­ç»ƒ+è¯„ä¼°)')
    parser.add_argument('--quick', action='store_true', help='å¿«é€Ÿæ¨¡å¼ï¼šå°† EPOCHS ä¸´æ—¶æ”¹ä¸º 3')
    parser.add_argument('--baseline_model', type=str, default='best_model.pth',
                        help='åŸºçº¿æ¨¡å‹æƒé‡è·¯å¾„ï¼ˆè¯„ä¼°æ—¶ä½¿ç”¨ï¼‰')
    parser.add_argument('--enhanced_model', type=str, default='best_model_enhanced.pth',
                        help='å¢å¼ºç‰ˆæ¨¡å‹æƒé‡è·¯å¾„ï¼ˆè¯„ä¼°æ—¶ä½¿ç”¨ï¼‰')
    args = parser.parse_args()

    # å¿«é€Ÿæ¨¡å¼ï¼šå‡å°è®­ç»ƒå‘¨æœŸ
    original_epochs = config.EPOCHS
    if args.quick:
        config.EPOCHS = 3
        print(f"âš¡ å¿«é€Ÿæ¨¡å¼å·²å¼€å¯ï¼šEPOCHS {original_epochs} -> {config.EPOCHS}")

    # ç»Ÿä¸€å‡†å¤‡ä¸€æ¬¡æ•°æ®åˆ’åˆ†ï¼ˆ9:1ï¼‰ï¼Œè¯„ä¼°æ—¶å¤ç”¨
    print("\nğŸ“‚ å‡†å¤‡æ•°æ® (9:1 éªŒè¯é›†ï¼Œå›ºå®š SEED=42)...")
    train_df, val_df = prepare_data()

    baseline_auc = None
    enhanced_auc = None

    if args.mode in ['train', 'all']:
        print("\n===== è®­ç»ƒï¼šåŸºçº¿æ¨¡å‹ =====")
        _model_b, _hist_b = train_baseline()
        print("\n===== è®­ç»ƒï¼šå¢å¼ºç‰ˆæ¨¡å‹ï¼ˆèåˆç‰¹å¾å·¥ç¨‹ï¼‰ =====")
        _model_e, _hist_e = train_enhanced()

    if args.mode in ['eval', 'all']:
        print("\n===== è¯„ä¼°ï¼šåŸºçº¿æ¨¡å‹ =====")
        baseline_auc, _probs_b, _preds_b = evaluate_model(args.baseline_model, val_df)
        print("\n===== è¯„ä¼°ï¼šå¢å¼ºç‰ˆæ¨¡å‹ =====")
        enhanced_auc, _probs_e, _preds_e = evaluate_enhanced_model(args.enhanced_model, val_df)

        # æ±‡æ€»CSV
        write_summary_csv(baseline_auc, enhanced_auc)

    # è¿˜åŸ EPOCHS è®¾ç½®
    config.EPOCHS = original_epochs


if __name__ == '__main__':
    main()
