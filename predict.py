"""
é¢„æµ‹å’Œè¯„ä¼°æ¨¡å—
"""
import torch
import numpy as np
import pandas as pd
from tqdm import tqdm
from sklearn.metrics import roc_auc_score, classification_report, confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns

from config import config
from model import create_model
from dataset import TextMatchDataset, get_dataloaders


@torch.no_grad()
def predict(model, dataloader, device):
    """
    å¯¹æ•°æ®è¿›è¡Œé¢„æµ‹
    è¿”å›æ¦‚ç‡å’Œé¢„æµ‹æ ‡ç­¾
    """
    model.eval()
    all_probs = []
    all_labels = []

    progress_bar = tqdm(dataloader, desc='Predicting')
    for batch in progress_bar:
        query1 = batch['query1'].to(device)
        query2 = batch['query2'].to(device)
        labels = batch['label']

        # å‰å‘ä¼ æ’­
        logits = model(query1, query2)
        probs = torch.sigmoid(logits).cpu().numpy()

        all_probs.extend(probs)
        all_labels.extend(labels.numpy())

    return np.array(all_probs), np.array(all_labels)


def evaluate_model(model_path, val_df):
    """
    åŠ è½½æœ€ä½³æ¨¡å‹å¹¶åœ¨éªŒè¯é›†ä¸Šè¯„ä¼°
    """
    print("\n" + "=" * 70)
    print("ğŸ“Š æ¨¡å‹è¯„ä¼°")
    print("=" * 70)

    # åŠ è½½æ¨¡å‹
    print(f"\nğŸ“¥ åŠ è½½æ¨¡å‹: {model_path}")
    checkpoint = torch.load(
        model_path, map_location=config.DEVICE, weights_only=False)

    model = create_model()
    model.load_state_dict(checkpoint['model_state_dict'])
    model = model.to(config.DEVICE)
    model.eval()

    print(f"   æ¨¡å‹æ¥è‡ª Epoch: {checkpoint['epoch']}")
    print(f"   æœ€ä½³ AUC: {checkpoint['best_auc']:.4f}")

    # å‡†å¤‡æ•°æ®
    from torch.utils.data import DataLoader
    val_dataset = TextMatchDataset(val_df, max_len=config.MAX_LEN)
    val_loader = DataLoader(
        val_dataset,
        batch_size=config.BATCH_SIZE,
        shuffle=False,
        num_workers=config.NUM_WORKERS,
        pin_memory=True
    )

    # é¢„æµ‹
    print("\nğŸ”® å¼€å§‹é¢„æµ‹...")
    probs, labels = predict(model, val_loader, config.DEVICE)
    preds = (probs > 0.5).astype(int)

    # è®¡ç®—æŒ‡æ ‡
    auc = roc_auc_score(labels, probs)

    print("\n" + "=" * 70)
    print("ğŸ“ˆ è¯„ä¼°ç»“æœ")
    print("=" * 70)
    print(f"\nğŸ¯ AUC Score: {auc:.4f}")

    print("\nğŸ“‹ åˆ†ç±»æŠ¥å‘Š:")
    print(classification_report(labels, preds,
          target_names=['ä¸åŒ¹é…', 'åŒ¹é…'], digits=4))

    # æ··æ·†çŸ©é˜µ
    cm = confusion_matrix(labels, preds)
    print("\nğŸ“Š æ··æ·†çŸ©é˜µ:")
    print(f"                é¢„æµ‹ä¸åŒ¹é…  é¢„æµ‹åŒ¹é…")
    print(f"å®é™…ä¸åŒ¹é…:      {cm[0][0]:>8}    {cm[0][1]:>8}")
    print(f"å®é™…åŒ¹é…:        {cm[1][0]:>8}    {cm[1][1]:>8}")

    # ç»˜åˆ¶æ··æ·†çŸ©é˜µ
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
                xticklabels=['ä¸åŒ¹é…', 'åŒ¹é…'],
                yticklabels=['ä¸åŒ¹é…', 'åŒ¹é…'])
    plt.xlabel('é¢„æµ‹æ ‡ç­¾')
    plt.ylabel('çœŸå®æ ‡ç­¾')
    plt.title(f'æ··æ·†çŸ©é˜µ (AUC: {auc:.4f})')
    plt.tight_layout()
    plt.savefig('confusion_matrix.png', dpi=150, bbox_inches='tight')
    print("\nğŸ“Š æ··æ·†çŸ©é˜µå›¾å·²ä¿å­˜åˆ°: confusion_matrix.png")

    # é¢„æµ‹åˆ†å¸ƒ
    plot_prediction_distribution(probs, labels)

    return auc, probs, preds


def plot_prediction_distribution(probs, labels):
    """ç»˜åˆ¶é¢„æµ‹æ¦‚ç‡åˆ†å¸ƒ"""
    fig, axes = plt.subplots(1, 2, figsize=(14, 5))

    # æŒ‰çœŸå®æ ‡ç­¾åˆ†ç»„çš„æ¦‚ç‡åˆ†å¸ƒ
    probs_neg = probs[labels == 0]
    probs_pos = probs[labels == 1]

    axes[0].hist(probs_neg, bins=50, alpha=0.6,
                 label='ä¸åŒ¹é… (label=0)', color='blue')
    axes[0].hist(probs_pos, bins=50, alpha=0.6,
                 label='åŒ¹é… (label=1)', color='red')
    axes[0].set_xlabel('é¢„æµ‹æ¦‚ç‡')
    axes[0].set_ylabel('æ ·æœ¬æ•°')
    axes[0].set_title('é¢„æµ‹æ¦‚ç‡åˆ†å¸ƒï¼ˆæŒ‰çœŸå®æ ‡ç­¾ï¼‰')
    axes[0].legend()
    axes[0].grid(True, alpha=0.3)

    # æ•´ä½“æ¦‚ç‡åˆ†å¸ƒ
    axes[1].hist(probs, bins=50, alpha=0.7, color='green')
    axes[1].axvline(x=0.5, color='red', linestyle='--',
                    linewidth=2, label='é˜ˆå€¼=0.5')
    axes[1].set_xlabel('é¢„æµ‹æ¦‚ç‡')
    axes[1].set_ylabel('æ ·æœ¬æ•°')
    axes[1].set_title('é¢„æµ‹æ¦‚ç‡æ•´ä½“åˆ†å¸ƒ')
    axes[1].legend()
    axes[1].grid(True, alpha=0.3)

    plt.tight_layout()
    plt.savefig('prediction_distribution.png', dpi=150, bbox_inches='tight')
    print("ğŸ“Š é¢„æµ‹åˆ†å¸ƒå›¾å·²ä¿å­˜åˆ°: prediction_distribution.png")


def save_predictions(probs, labels, output_file='predictions.csv'):
    """ä¿å­˜é¢„æµ‹ç»“æœ"""
    df = pd.DataFrame({
        'true_label': labels,
        'predicted_prob': probs,
        'predicted_label': (probs > 0.5).astype(int)
    })
    df.to_csv(output_file, index=False)
    print(f"\nğŸ’¾ é¢„æµ‹ç»“æœå·²ä¿å­˜åˆ°: {output_file}")


if __name__ == '__main__':
    from dataset import prepare_data

    # å‡†å¤‡æ•°æ®
    train_df, val_df = prepare_data()

    # è¯„ä¼°æ¨¡å‹
    auc, probs, preds = evaluate_model(config.MODEL_SAVE_PATH, val_df)

    # ä¿å­˜é¢„æµ‹ç»“æœ
    save_predictions(probs, val_df['label'].values)
