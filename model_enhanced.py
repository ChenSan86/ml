"""
å¢å¼ºç‰ˆæ–‡æœ¬åŒ¹é…æ¨¡å‹ï¼šèåˆæ·±åº¦å­¦ä¹ ç‰¹å¾å’Œæ‰‹å·¥ç‰¹å¾
"""
import torch
import torch.nn as nn
import torch.nn.functional as F
from config import config
from model import SiameseEncoder, InteractionLayer
from features import FeatureExtractor


class EnhancedTextMatchModel(nn.Module):
    """
    èåˆæ·±åº¦å­¦ä¹ ç‰¹å¾å’Œæ‰‹å·¥ç‰¹å¾çš„æ–‡æœ¬åŒ¹é…æ¨¡å‹
    """
    
    def __init__(self, vocab_size, embed_dim, hidden_dim, num_layers, dropout, feature_dim=19):
        super(EnhancedTextMatchModel, self).__init__()
        
        # å­ªç”Ÿç¼–ç å™¨ï¼ˆæ·±åº¦å­¦ä¹ ç‰¹å¾ï¼‰
        self.encoder = SiameseEncoder(vocab_size, embed_dim, hidden_dim, num_layers, dropout)
        
        # äº¤äº’å±‚
        self.interaction = InteractionLayer(hidden_dim)
        
        # ç‰¹å¾æå–å™¨
        self.feature_extractor = FeatureExtractor()
        
        # æ‰‹å·¥ç‰¹å¾å¤„ç†å±‚
        self.feature_processor = nn.Sequential(
            nn.Linear(feature_dim, 128),
            nn.BatchNorm1d(128),
            nn.ReLU(),
            nn.Dropout(dropout),
            nn.Linear(128, 64),
            nn.BatchNorm1d(64),
            nn.ReLU(),
            nn.Dropout(dropout)
        )
        
        # æ·±åº¦å­¦ä¹ äº¤äº’ç‰¹å¾ç»´åº¦
        interaction_dim = hidden_dim * 3 + 1
        
        # èåˆå±‚ï¼šæ·±åº¦å­¦ä¹ ç‰¹å¾ + æ‰‹å·¥ç‰¹å¾
        fusion_dim = interaction_dim + 64
        
        # æœ€ç»ˆåˆ†ç±»å™¨
        self.classifier = nn.Sequential(
            nn.Linear(fusion_dim, 512),
            nn.BatchNorm1d(512),
            nn.ReLU(),
            nn.Dropout(dropout),
            nn.Linear(512, 256),
            nn.BatchNorm1d(256),
            nn.ReLU(),
            nn.Dropout(dropout),
            nn.Linear(256, 128),
            nn.ReLU(),
            nn.Dropout(dropout),
            nn.Linear(128, 1)
        )
        
        # åˆå§‹åŒ–æƒé‡
        self._init_weights()
        
        # ç”¨äºç‰¹å¾æ ‡å‡†åŒ–çš„ç»Ÿè®¡é‡
        self.register_buffer('feature_mean', None)
        self.register_buffer('feature_std', None)
    
    def _init_weights(self):
        """åˆå§‹åŒ–æ¨¡å‹æƒé‡"""
        for module in self.modules():
            if isinstance(module, nn.Linear):
                nn.init.xavier_uniform_(module.weight)
                if module.bias is not None:
                    nn.init.zeros_(module.bias)
            elif isinstance(module, nn.BatchNorm1d):
                nn.init.ones_(module.weight)
                nn.init.zeros_(module.bias)
            elif isinstance(module, nn.Embedding):
                nn.init.uniform_(module.weight, -0.1, 0.1)
                if module.padding_idx is not None:
                    module.weight.data[module.padding_idx].zero_()
    
    def forward(self, query1, query2, handcrafted_features=None):
        """
        å‰å‘ä¼ æ’­
        
        Args:
            query1, query2: [batch_size, seq_len]
            handcrafted_features: [batch_size, feature_dim] å¯é€‰çš„é¢„è®¡ç®—ç‰¹å¾
        
        Returns:
            logits: [batch_size]
        """
        batch_size = query1.size(0)
        
        # 1. æ·±åº¦å­¦ä¹ ç‰¹å¾
        # ç¼–ç ä¸¤ä¸ªå¥å­
        repr1, _ = self.encoder(query1)
        repr2, _ = self.encoder(query2)
        
        # è®¡ç®—äº¤äº’ç‰¹å¾
        dl_features = self.interaction(repr1, repr2)  # [batch_size, interaction_dim]
        
        # 2. æ‰‹å·¥ç‰¹å¾
        if handcrafted_features is None:
            # å®æ—¶æå–æ‰‹å·¥ç‰¹å¾
            handcrafted_features = self.feature_extractor.extract_batch_features(
                query1, query2
            ).to(query1.device)
        
        # æ ‡å‡†åŒ–æ‰‹å·¥ç‰¹å¾
        if self.training:
            # è®­ç»ƒæ—¶è®¡ç®—å¹¶æ›´æ–°ç»Ÿè®¡é‡
            if self.feature_mean is None or self.feature_std is None:
                self.feature_mean = handcrafted_features.mean(dim=0, keepdim=True)
                self.feature_std = handcrafted_features.std(dim=0, keepdim=True)
                self.feature_std = torch.where(
                    self.feature_std == 0, 
                    torch.ones_like(self.feature_std), 
                    self.feature_std
                )
            else:
                # ä½¿ç”¨ç§»åŠ¨å¹³å‡æ›´æ–°ç»Ÿè®¡é‡
                momentum = 0.1
                batch_mean = handcrafted_features.mean(dim=0, keepdim=True)
                batch_std = handcrafted_features.std(dim=0, keepdim=True)
                self.feature_mean = (1 - momentum) * self.feature_mean + momentum * batch_mean
                self.feature_std = (1 - momentum) * self.feature_std + momentum * batch_std
        
        if self.feature_mean is not None and self.feature_std is not None:
            handcrafted_features = (handcrafted_features - self.feature_mean) / self.feature_std
        
        # å¤„ç†æ‰‹å·¥ç‰¹å¾
        hc_features = self.feature_processor(handcrafted_features)  # [batch_size, 64]
        
        # 3. ç‰¹å¾èåˆ
        fused_features = torch.cat([dl_features, hc_features], dim=1)
        
        # 4. åˆ†ç±»
        logits = self.classifier(fused_features)
        
        return logits.squeeze(-1)  # [batch_size]


def create_enhanced_model():
    """åˆ›å»ºå¢å¼ºç‰ˆæ¨¡å‹å®ä¾‹"""
    model = EnhancedTextMatchModel(
        vocab_size=config.VOCAB_SIZE,
        embed_dim=config.EMBED_DIM,
        hidden_dim=config.HIDDEN_DIM,
        num_layers=config.NUM_LAYERS,
        dropout=config.DROPOUT,
        feature_dim=19  # æ‰‹å·¥ç‰¹å¾ç»´åº¦
    )
    
    # è®¡ç®—å‚æ•°é‡
    total_params = sum(p.numel() for p in model.parameters())
    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
    
    print(f"\nğŸ—ï¸  å¢å¼ºç‰ˆæ¨¡å‹åˆ›å»ºå®Œæˆ:")
    print(f"   æ€»å‚æ•°é‡: {total_params:,}")
    print(f"   å¯è®­ç»ƒå‚æ•°: {trainable_params:,}")
    print(f"   æ‰‹å·¥ç‰¹å¾ç»´åº¦: 19")
    
    return model


if __name__ == '__main__':
    # æµ‹è¯•æ¨¡å‹
    model = create_enhanced_model()
    model.to(config.DEVICE)
    
    # æµ‹è¯•å‰å‘ä¼ æ’­
    batch_size = 4
    seq_len = 60
    query1 = torch.randint(1, 1000, (batch_size, seq_len)).to(config.DEVICE)
    query2 = torch.randint(1, 1000, (batch_size, seq_len)).to(config.DEVICE)
    
    outputs = model(query1, query2)
    print(f"\nğŸ” æ¨¡å‹æµ‹è¯•:")
    print(f"   Input shape: [{batch_size}, {seq_len}]")
    print(f"   Output shape: {outputs.shape}")
    print(f"   Sample outputs: {outputs[:3]}")
